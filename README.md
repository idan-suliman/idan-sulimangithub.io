האוניברסיטה הפתוחה
המחלקה למתמטיקה ולמדעי המחשב
סמינר באנליזה נומרית
מחוללי אקראיות
 
כתב עידן סולימן ת.ז 212229132
בהדרכתו של ד"ר עידן אלתר
תוכן עניינים
פרק 1 הקדמה...............................................................................................................1

פרק 2 RNG אחיד ........................................................................................................2
2.1 מבוא........................................................................................................................2
2.2 Linear congruential generator................................................................................2
2.3 Diehard tests..........................................................................................................4
2.3.1 שיטות עיקריות........................................................................................................5

פרק 3 שיטת ההיפוך.....................................................................................................9
3.1 הגדרות ומושגים.........................................................................................................9
3.2 שיטות מרכזיות.........................................................................................................10

פרק 4 שיטת Alias.....................................................................................................16
4.1 הקדמה...................................................................................................................16
4.2 טרמינולוגיה ומושגים מתמטית....................................................................................16
4.3 הדמיית קובייה הגונה................................................................................................17
4.4 הדמיית קובייה לא הגונה בעזרת קובייה הגונה...............................................................17
4.5 הדמיית מטבע מוטה..................................................................................................19
4.6 הדמיית קובייה הגונה בעזרת מטבע מוטה.....................................................................19
4.7 הדמיית קובייה לא הגונה בעזרת מטבע מוטה................................................................20
4.8 הכללת מטבע מוטה להדמיית קובייה לא הגונה..............................................................22
4.9 הדמיית קובייה לא הגונה בעזרת מטבע מוטה וקובייה הגונה............................................26
4.10 שיטת Alias...........................................................................................................30

פרק 5 שיטת הדחייה...................................................................................................33
5.1 שיטת הדחייה להתפלגות רציפה.................................................................................33
5.2 שיטת הדחייה להתפלגות דיסקרטית............................................................................38

פרק 6 אלגוריתם הזיגורט............................................................................................40
6.1 תיאור השיטה...........................................................................................................40
ביבליוגרפיה................................................................................................................44
 
פרק 1 הקדמה
במסגרת עבודת הסמינר נחקור את עולם המספריים האקראיים, תחום שמעסיק מדענים רבים בכול העולם מזה שנים רבות, לא נאמוד את חשיבות של המספרים האקראיים בתחום המחשבים רק נציין שהם משמשים לגוון מטרות כמו אבטחת מידע ברשת, נבואי והצגת תוצאות יציבות.
נבחן את האתגרים שנוצרים ביצירת רצף אקראי של מספרים בניגוד למחשבים דטרמיניסטיים שפחות נפוצים כיום, נציג את האלגוריתמים והשיטות המיועדות ליצירת סדרות מספרים אקראיות של מספרים שלמים בלבד.
תכנית הפעולה שלנו היא להניח שיש לנו מקור רנדומליות בעל התפלגות אחידה בקטע [0,1] ועל סמך המקור הזה נייצר מקורות מגוונים של רצפי אקראיות בהתפלגויות שונות במסגרת העבודה נסקור רק מקורות פסאודו-אקראיים (pseudo random) להבדיל ממקורות אקראיות טהורים (true random).
יתר על כן, כל שיטה שנציג המטרה העליונה שלנו תהיה לייעל כמה שיותר את השיטה תוך שימוש בכלים אלגבריים, גיאומטריים ויכולות חומרה תוכנה. כך שהשיטה תעניק מספר אקראי תוך איטרציה בודדת, לדוגמא במחולל לינארי שיוצג בפרק השני נראה איך ליצור מספר אקראי ברצף תוך איטרציה בודדת.
בנוסף, נמדוד את איכותם של מחוללי המספרים באמצעות כמות החזרות, ובכך נתאר את פעולת האלגוריתם בדרך סטטיסטית. על אף שהמחוללים נבדקים בדרך סטטיסטית, יש תמיד את האפשרות למצוא מבחן סטטיסטי המצביע על פגם. מבחנים אלו דומים למערכות כמותיות עם התפלגות ידועה, וכך מספק פלטפורמה מאוד עמידה ופרקטית ליצירת סדרות אקראיות.
לסיכום, נתבקש להבין שבניית אלגוריתמים למחולל אקראיות איכותי היא משימה קשה שדורשת מומחיות בתחום התאוריה המספרית והקומבינטוריקה.








פרק 2  RNG אחיד
2.1 מבוא
מספרים פסאודו אקראיים משמשים במחשבים ומתמטיקה למגוון מטרות חשובות השימוש בהם רחב כגון בתחום האבטחה, מספרים אקראיים משמשים ליצירת מפתחות לאבטחת מידע, כך שיהיה קשה מאוד לנבא ולחקות אותו. כמו כן, באלגוריתמים והדמיות, השימוש במספרים אקראיים יכול לשפר את הביצועים וליצור תוצאות יציבות ומיוצגות.
אחת השיטות הנפוצות ליצירת מספרים אקראיים היא באמצעות מחולל מספרים אקראי לינארי LCG . (LCG) הוא אלגוריתם יחסית פשוט שיוצר רצף של מספרים אקראיים בצורה יעילה וחסכונית.
המחולל האקראי הלינארי הוא בחירה נפוצה בשל קלות החישוב והפשטות של האלגוריתם. במערכות עם משאבים מוגבלים וביישומים שדורשים בפשטות מספרים אקראיים,LCG  מתאים.
למרות יתרונותיו, יש לשים לב שהשימוש במחולל אקראיות לינארי לא תמיד מתאים לכל היישומים, ויתכן שייצור בעיות כאשר נדרשים מספרים אקראיים באיכות גבוהה יותר, כמו במחולל אקראיות קריפטוגרפים. במקרים כאלו, נעדיף להשתמש באלגוריתמים יותר מתקדמים ובטוחים שנשענים על True Random.
ההבדל בין מספרים פסאודו אקראיים לבין True Random הוא שפסאודו משתמשת באלגוריתם ליצירת מספרים אקראיים, ואף שהם נראים אקראיים, יש להם סדר חוזר וניתן לחזור על אותם ערכים גם אם המחזור גדול מאוד True Random .משתמשת בתופעות פיזיקליות אמתיות (כמו רעש קוונטי, פיגור שעון, מנורת לבה) ויוצרת מספרים אקראיים שאין להם סדר חוזר ולא ניתן לחזור על אותם ערכים. בעבודה זאת נתמקד רק במספרים פסאודו אקראיים.

2.2 Linear congruential generator
מחולל לינארי אקראי הוא אלגוריתם ליצירת רצף של מספרים אקראיים, המתבצע באמצעות נוסחאות לינאריות\אפיניות.
השיטה הוצגה לראשונה ע"י דריק הנרי להמר בשנת 1951 במאמרו
"Mathematical methods in large-scale computing units" עמודים 141-146
נרצה לבחור m החילוק בשארית (mod), 0<m
                 a המקדם של x_n, 0≤a<m
                 c המקדם החופשי, 0≤c<m
                x_0 ערך התחלתי, 0≤x_0<m
רצף המספרים הפסאודו האקראיים 〈x_n 〉 מתקבל ע"י הנוסחה:
x_(n+1)=(ax_n+c)mod m
הפעולה של המודולו m דומה מאוד לקביעת היכן ינחת כדור בגלגל רולטה מסתובב.
לדוגמא נבחר: m=10,c=x_0=a=7 נקבל את הרצף:
7,6,9,0,7,6,9,0,…
אנו למדים כי לא כל בחירה של פרמטרים תניב רצף מספרים אקראי נרצה לבצע בחירה מושכלת וזהירה של פרמטרים.
מהדוגמא נוכל לראות שכל רצף שנוצר ע"י הנוסחה הרקורסיבית הוא באורך מחזור כלשהו גדול ככול שיהיה.
בחירה של a:
נוכל לשלול מקרה בו a=1 כי אז נקבל 〖(x〗_0+nc)mod m שכמובן אינו אקראי, מקרה גרוע אף יותר הוא a=0 שבו הרצף קבוע.
לכן נרצה לבחור a≥2.
בחירה של m:
במחולל לינארי אקראי הבחירה של m מאוד חשובה מכיוון שm- מציין את אורך הרצף המקסימלי,m  מציין את הmod- כלומר מציין את כמות מחלקות השאריות המקסימליות למשוואה x_0+nc ובכך יש לכול היותר m שאריות לחלוקה בm-. מהירות ייצור הרצף גם היא מושפעת מבחירת m כיוון שהמחשב עובד בבסיס בינארי אם נבחר m מהצורה 2^i המחשב ימיר את המספרים במהירות יותר לקלים להבנה, פעולת ההכפלה של מספרים מתבצעת מהר יותר לא ע"י פעולות מתמטיות מתקדמות אלה בהזזת ביטים ועוד המון יתרונות לעבודה עם m מהצורה 2^i.
(בספר של קנותThe Art of Computer Programming  ' תוכלו למצוא ביתר פירוט)
-מושגים-
כעת נסקור את תכונות המחולל האקראי שמעידות על איכות המספרים האקראיים שהוא מפיק. נעיין במחזוריות המציינת את תדירות חזרתם של המספרים, בטווח שבו הם פועלים, ובחירת פרמטרים חכמה. הבנת התכונות הללו חיונית להבטחת איכות וביטחון בייצור מספרים פסאודו אקראיים.
מחזוריות המחולל חוזר על אותו רצף לאחר מספר מסוים של צעדים, תלוי בx_0 ובפרמטרים נוספים.
טווח והתפלגות אחידה כאשר ידוע כי הטווח מושפע מהm- מודולו של הנוסחה נצפה כי כאשר נריץ את הנוסחה הרצף האקראי יהיה אחיד ומפוזר על גבי הטווח.
מהירות המחולל מאיץ את קצב יצירת המספרים האקראיים כאשר m הוא 2^i כאשר i טבעי, בגלל תכונות החומרה שמשתמשת בבסיס בינארי לייצוג מספרים.
בחירת פרמטרים נכונה כדי להשיג רצף של מספרים אקראיים באיכות טובה, יש לבחור בזהירות פרמטרים נכונים. פרמטרים "גרועים" יכולים להוביל למחזוריות קצרה יחסית ולהתפלגות שאינה אחידה.
הרצון למקסם את האחידות יכול ליצור מספרים אקראיים שאינם חוזרים על עצמם. הרצון למקסם גם את הרצף מבטיח שיצירת המספרים האקראיים תהיה יעילה, תוך ששמים דגש על ביצועים כעת נתעמק בכלים פרקטיים למקסום התכונות הללו של המחולל הלינארי שהצגנו כאן.
עד כה ראינו כי בחירה של  a≥2 וm  גדול למדיי הן המפתח לאקראיות אך אם זאת שני תנאים אלו אינם מספיקים, לכן נפתח במשפט מרכזי כדי למקסם אורך מחזור.
משפט-הול ודובל מבטיח כי אורך המחזור יהיה המקסימלי כלומר בדיוק m אם ורק אם:
	gcd(m,c)=1 , כלומר גדול המחלקים המשותפים של m וc-.
	אם p ראשוני במתחלק בm  אז גם מתחלק בa-1 .
	אם 4 מתחלק בm  אז 4 מתחלק גם ב a-1.
נחלק למספר מקרים נפוצים של המכולל:
כאשר m=2^i לi  טבעי, c≠0  :האורך מחזור המקסימלי שניתן להשיג 2^i 
אם a=1+4k לk  טבעי וגם gcd(m,c)=1.
כאשר m=2^i לi  טבעי, c=0  :האורך מחזור המקסימלי שניתן להשיג m/4=2^(i-2)
אם x_0 אי-זוגי וגם a=5+8k או a=3+8k  ל k טבעי.
כאשר m ראשוני, c=0: אורך המחזור המקסימלי שניתן להשיג m-1
אם הk- הקטן ביותר כך שם a^k-1 מתחלק בm- הוא k=m-1.
ראינו כי יש כמה מקריים מרכזיים אשר מבטיחים רצף ייצור של רצף אקראי, אם זאת לא תמיד כולן טובות ואלו רק חלק מהאפשרויות לייצור רצף לינארי.

2.3 Diehard tests
עולם החקר והניתוח הסטטיסטי עשוי לספק לנו כלי חשוב להבנה עמוקה של התנהגותו של מחולל לינארי אקראי אפשר לבדוק כלים אלו לכול מחולל בין אם הוא לינארי או לא, בסעיף זה נתמקד במחוללים ליניאריים בלבד אך שיטות אלו יכולות להתאים לכל מחולל.
מחולל לינארי אקראי מהווה מקור עשיר של מספרים אקראיים עד כה עסקנו רק בסוגיה איך להגדיל את המחזור של הרצף אבל כעת נדון בשאלה עד כמה איכותי ואקראי המחזור, ובכך נשאל האם ניתן לסמוך על המחולל הלינארי? בסעיף זה, נחקור איך מבחנים סטטיסטים יכולות לעזור לנו לקבוע ולהבין את תכונותיו של המחולל.
בסעיף זה נעסוק בסדרת שיטות בשם "Diehard tests"  המיועדות לבדוק את אקראיותו של מחולל מספרים, נדגיש כי מבחנים סטטיסטיים אלו אינן יעידו על איכות המחולל. השיטות נכתבו ע"י ג'ורג' מרסגליה ורוברט הרמן בשפת  Cופורסמו לראשונה בשנת 1995 שהוביל לפיתוח ספריית TestU01 שקיום נפוצה מאוד לבדיקת אקראיות של רצף מספרים.
(בספרו של ג'ורג' מרסגליה "The Marsaglia Random Number CDROM including the Battery of Tests of Randomness" תוכלו למצוא ביתר פירוט)
השם "Diehard" מתייחס לכך שהבדיקות נועדו להיות מסקרנות ומודרניות, כדי לבדוק את עמידותם של מחוללי המספרים כמו גם לזהות בעיות באלגוריתמים המייצרים מספרים אקראיים.
2.3.1 שיטות עיקריות
מבחן כללי ללמוד על אקראיות של נתונים
מבחן chi-square יסומן χ^2 הוא אולי המבחן המוכר ביותר מבין כל המבחנים הסטטיסטיים.
מבחן χ^2 היא שיטה בסיסית שמנוצלת כמעט בכל המבחנים המתקדמים לבניית מבחן סטטיסטי. 
נביא דוגמא שממחישה את המבחן, נזרוק 2 קוביות הגונות במקביל ונייצג בS- את סכום המספרים שייצאו בהטלות, נבדוק מה ההסתברות שלכל אחד מהאפשרויות של S:
12	11	10	9	8	7	6	5	4	3	2	S
1/36	1/18	1/12	1/9	5/36	1/6	5/36	1/9	1/12	1/18	1/36	p_S


נצפה לכל S יהיה n∙p_S הופעות לכל n הטלות של הקוביות.
12	11	10	9	8	7	6	5	4	3	2	S
6	9	14	15	21	29	22	12	10	4	2	Y_S
4	8	12	16	20	24	20	16	12	8	4	〖n∙p〗_S


כעת נחשב את הערך של V ע"י הנוסחה הבאה:
V=∑_(S=1)^k▒〖(Y_S-n∙p_S)〗^2/(n∙p_S )
מספר דרגות החופש של V נקבע ע"י מספר האפשרויות של S פחות אחד כלומר k-1
נחפש בטבלה את הערך המתאים:
5
	0.995	0.99	0.975	0.95	0.90	0.10	0.05
	0.025	0.01	0.005
1	---	---	0.001	0.004	0.016	2.706	3.841		5.024	6.635	7.879
2	0.010	0.020	0.051	0.103	0.211	4.605	5.991		7.378	9.210	10.597
3
0.072	0.115	0.216	0.352	0.584	6.251	7.815		9.348	11.345	12.838
4	0.207	0.297	0.484	0.711	1.064	7.779	9.488		11.143	13.277	14.860
(הטבלה המלאה - נספח 1)
נרצה שהמרחק בין הערך המצופה לבין הערך שהתקבל יהיה גדול כך שV ̅ יגדל וכך נקבע כי המבחן שייצרנו לרצף אקראי יותר.
נביא עוד דוגמא בה יש 2 ניסויים נפרדים V_1,V_2:
12	11	10	9	8	7	6	5	4	3	2	S
13	14	13	11	18	18	20	13	10	10	4	V_1
5	9	13	17	21	24	19	15	11	7	3	V_2

ונחשב את ערכי V_1,V_2 לפי הנוסחה למציאת V נקבל V_1=29 59/120,V_2=1 17/120
אנו רואים כי V_2 קטן מאוד כל כך קטן שלא נוכל לצפות לתוצאות אקראיות בכלל לא נוכל למצוא ערך מתאים בטבלה.
כלומר רק מספר הדרגות משפיע על התוצאה, הטבלה של chi מדויקת ככול שמספר הזריקות n גדול יותר, לא נוכל לענות במדויק עד כמה n צריך להיות גדול לכן בכל מבחן נגדיר n גדול כך שיתאים להיות חיקוי אחר ההתפלגות שרצינו, כמובן במסגרת החומרה והתוכנה.
מצד שני, בחירה גדולה יותר מידי של n יכולה לטשטש אי-אקראיות של רצף לכן נשאף להריץ את המבחן כמה פעמים ברצף כדי לכסות על האפשרות שהייתה טשטוש אי-אקראיות במודל.
נוכל לסכם את המבחן כך: נבחר n מספיק גדול לקלט אקראי מתוך הרצף, נספור כמה מכל אחד ממספרי הקלט נופל לתוך k קטגוריות שונות, נבדוק את דרגת V (בדיוק k-1) נחשב את V ונחפש את העמודה המתאימה בטבלה אם קיבלנו ערך קטן מ1% או גדול מ99% נפסול את האפשרות לאקראיות של הרצף, ישנם תחומים אחרים כמו לדוגמא חשוד: 1%-5% או 95%-99% שבהם נעדיף לא לפסול באופן מידי את המבחן.
הערה: לפעמים במבחנים שנראה בהמשך נרצה להביא התפלגות ספציפית לדוגמא התפלגות פואסונית ובכך נרצה לבדוק עד כמה הרצף הנוכחי מחקה את ההתפלגות הרצויה בצורה פרקטית ככול שהערך V קטן יותר כך ההתפלגות הנוכחית מתחקה אחרי ההתפלגות הרצויה
כחלק מהמחקר של מבחני Diehard tests נתאר כעת 5 מבחנים מרכזיים של השיטה כחלק מה-11 מבחנים והם: רווח ימי הולדת, בדיקת דרגה למטריצה בינארית, בדיקת זרם ביטים, לספור את מספר ה-1 ברצף, חפיפת חמישיות סדורות.
כל אחת מהמבחנים בודקת תכונה ספציפית של המספרים האקראיים שנוצרים על ידי המחולל.
רווח ימי הולדת
רווח ימי הולדת היא שיטה אמינה מאוד לבדיקת אמינות של המחולל כלומר השיטה תבדוק האם המחולל יוצר מספרים בצורה "מספיק" אקראית (הכלי בודק רק אם יש בעיה באמינות האקראיות ולא משווה בין מקראיות של מחוללים)
נפרט את ההליך שלב אחר שלב –
שלב א – הנחות
נריץ את המחולל הלינארי עד לקבלת סדרת ערכים אקראיים נסמנו 〖〖〖{x〗_j}〗^n〗_(j=1)
מבחני המציאות מראים כי n≥2^18 כדי שנוכל להשוואת את ההסתברות להתפלגות פואסון. נבחר n=2^24 זהו מספר המספרים שהמחולל יצור.
ונבחר m=2^10 זהו גודל הטווח של המספרים שהמחולל יוצר כלומר בדיוק אותו m במסמן את המודולו בנוסחה הלינארית.
שלב ב – יצירת רווחים
נגדיר סדרה של מספרים 〖〖〖{y〗_j}〗^(n-1)〗_(j=1) כאשר y_j=x_j-x_(j+1).
שלב ג – בדיקת כפילויות
נבדוק כמה מבין איברי הסדרה 〖〖〖{y〗_j}〗^(n-1)〗_(j=1) חוזרים על עצמם יותר מפעם אחת (שהם y_m) נציב כ-l את מספר ההופעות
שלב ד – חישוב התוחלת
נחשב את התוחלת של התפלגות פואסון בפרמטר l :  P(l)=(e^(-m)∙m^l)/((l)!) 
במילים אחרות נחפש מה ההסתברות שיופיע הרווח 〖,y〗_m  פעמים lבמרחב המספרים בגדול m.
שלב ה – מציאת p'
נמצא את  V(מבחן χ^2)
את ערך הסף p' נקבל ממבחן חיצוני בשם שאותו לא נתאר כאן
שלב ו – המבחן הסטטיסטי
ניצור מבחן סטטיסטי עם השערה המורכבת:
H_0:p'≤p(l)
H_1:p'>p(l)
שלב ז – הכרעה
נסמן אזור דחייה וקבלה על הציר וע"פ הערך שניתן ל p' נוכל להכריע במבחן.
חפיפת חמישיות סדורות
במסגרת הסעיף, נציג שיטת בדיקה של ערכים אקראיים שנוצרים על ידי מחולל לינארי. 
המבחן בודק תכונות אקראיות ברצף של מיליון מספרים בפורמט 32 ביט. המבחן מתבצע על סדרה של 1,000,000 מספרים אקראיים שיוצרו ע"י המחולל, כל חמישה מספרים רצופים יכולים להיות אחד מ 120 מצבים אפשריים (כמספר הסידורים של סדרה עם חמש איברים !5).
לאחר בניית הסדרה, המבחן מבצע מעקב אחרי מעברים בין המצבים וסופר כמה פעמים כל מצב התרחש. לאחר מכן, המבחן בודק את ההתאמה בין התפלגות המצבים הנמדדת להתפלגות הנורמלית באמצעות מבחן χ^2 .
בדיקת דרגה למטריצה בינארית
השיטה דוגמת מספר גדול של מטריצות n×m (בד"כ 4000 ומעלה) כך שכל מטריצה היא בינארית שהוגדרה ע"י המחולל לכל מטריצה יש דרגה 0≤r≤n ניצור מערך A בגודל r שישמש בcounter שיוגדר כאפסים בהתחלה. יהי מטריצה שהמחולל יצא שדרגתה היאi  לכן  A[i]=A[i]+1. המשתנה שנגדיר למבחן הסטטיסטי יהיה דרגת המטריצה המבחן תלוי בגודל המטריצה נראה גדלים שונים:
1. ניקח זרם ביטים 31×31 כמטריצה מהמחולל אז הדרגות שבאופן הסתברותי יותר נדירות הן כל דרגה קטנה מ-28.
2. ניקח זרם ביטים 32×32 כמטריצה מהמחולל אז הדרגות שבאופן הסתברותי יותר נדירות הן כל דרגה קטנה מ-29.
3. ניקח זרם ביטים 6×8 כמטריצה מהמחולל אז הדרגות שבאופן הסתברותי יותר נדירות הן כל דרגה קטנה מ-4.
בכל אחד מהמקרים נייצר מבחן סטטיסטי הנתמך על מבחן χ^2 להכרעה במבחן.
בדיקת זרם ביטים
יהי רצף האקראי של המחולל באורך 2^21 שנקרא בין היתר רצף ביטים, ניקח סדרות של 20 אותיות מהרצף כך שהסדרה הראשונה מהמקום הראשון עד העשרים הסדרה השנייה מהמקום השני עד המקום העשרים ואחת וכן אלה..
נחפש את מספר הסדרות אינן מופיעות בכלל ברצף ואותן נספור השיטה אומרת שהמספר הצפוי הוא 144909 ובכך נוכל ליצור מבחן χ^2 מתאים.
לספור את מספר ה-1 ברצף
השיטה מציעה להסתכל על רצף של ביטים ולהתייחס למקומות שבהם מופיע 1.
דבר ראשון כל ביט יכול להכיל 0-8 פעמים את הספרה 1 הסתברות של (לפי המיקום בביט): 
1⁄256,8⁄256,28⁄256,56⁄256,70⁄256,56⁄256,28⁄256,8⁄256,1⁄256
לאחר מכן הרצף מומר לסדרות של 5 איברים כלומר מילים, באנלוגיה לשיטת החפיפה .

כל סדרה מקבלת ערך A,B,C,D,E  (הקלט הוא כמספר ה-1 בביט הנוכחי) לפי הפונקציה הבאה:







נמיר את הרצף המקורי לרצף של אותיות לפי הפונקציה שהגדרנו. יהי 256,000 מילים
באורך 5, יש 5^5 אפשרויות למילים שונות באורך 5.
המבחן מבצע מעקב אחרי מעברים בין המילים וסופר כמה פעמים כל מצב מילה הופיעה. לאחר מכן, המבחן בודק את ההתאמה בין התפלגות המילים הנמדדות להתפלגות הנורמלית באמצעות מבחן χ^2 .
פרק 3 שיטת ההיפוך
3.1 הגדרות ומושגים
שיטת ההיפוך מהווה כלי בסטטיסטיקה ובמדעי המחשב המשמש ליצירת מספרים אקראיים לפי התפלגות נתונה. באמצעות השיטה, אנו בוחרים באופן אקראי יחס מסוים מתחת לעקומה הסטטיסטית ומחזירים את הערך המתאים בתחום כך שהיחס שנבחר יהיה בדיוק היחס של השטח מתחתיו. מבחינה אינטואיטיבית, ייתכן שלא נבחר באופן נפוץ ערכים בקצוות ההתפלגות הכיוונים, שכן השטח באזורים אלו קטן מאוד, דבר שדורש בחירת ערכים קרובים מאוד לאפס או לאחד.
בקרבת החישובים, השיטה מכילה את חישוב פונקציית הצפיפות של התפלגות המצטברת, ואין כל קשר ישיר למונח "ההתפלגות". הפונקציה הזו מתארת את הצפיפות הסביבה של ערך מסוים בתחום התפלגות הנתונה. תהליך ההתפלגות הכללית משתמש בחישוב הפונקציה הזו ובהופכית שלה כחלק מהשלבים ביצירת מספרים אקראיים. יש לציין שבמקרה של התפלגות דיסקרטית, הפונקציה ההופכית הכוללת לא תמיד נדרשת, והחישוב עשוי להיות יחסית יעיל.
תחילה ניגש למושגים ומונחים כדי שנוכל לבנות את השיטה:
יהיה X משתנה מקרי רציף אם קיימת פונקציה אי-שלילית f לכל x∈R כך ש:
F(x)=P{x∈B}=∫_B▒〖f(x)dx〗
הפונקציה f נקראת בין היתר פונקציה צפיפות של המשתנה המקרי X, F(x) תקרא פונקציית ההתפלגות המצטברת.
נגדיר את הפונקציה ההופכית F(x):
F^(-1) (u)=inf⁡{x∶F(x)=u ,0<u<1}
כלומר נכניס ערך u המתפלג אחיד בקטע [0,1] ונקבל בחזרה ע"י הפונקציה ההופכית את הx- המשתנה הקטן ביותר שעד אליו השטח מתחת לגרף של פונקציה הצפיפות. יתר על כן  〖 F〗^(-1) (u)מתפלג בדיוק לפי פונקציית הצפיפות של f. איור להמחשה כאשר ההתפלגות מערכית עם פרמטר λ=1.


נוכיח שההתפלגות של F^(-1) (u) היא אכן ההתפלגות של פונקציית הצפיפות f
כעת נוכיח את אינטואיציה שראינו למעלה כלומר באופן טבעי למדיי F^(-1) (u)   מתפלג ע"פ פונקציית הצפיפות של f , מכיוון ש F^(-1) היא הפונקציה ההופכית של F נקבל כי F(F^(-1) (u))=u ובנוסף F^(-1) (F(x))=x אז בהכרח ההתפלגות של F^(-1) (u) היא פונקציית הצפיפות של f.

כאשר לא נוכל למצוא ישירות את F^(-1)  נתמקד בשיטות נומריות כדי למצוא פתרון לא אנליטי של המשוואה F(x)=u ובכך נעריך את הפונקציה F^(-1) (u), לא נרחיב על שיטות אלו כאן.

3.2 שיטות מרכזיות
כעת נתעסק בפיתוח השיטות לחישוב הרצף האקראי לסוגים שונים של התפלגויות. 
-שיטת ההיפוך להתפלגות דיסקרטית-
נפתח את האלגוריתם הבסיסי ביותר של השיטה ובהמשך הדרך נעזר בו כדי לפתח כלים מתקדמים יותר. בשיטת ההיפוך אנחנו מייצרים מספר אקראי U∈[0,1] ומחפשים את הערך X כך ש: F^(-1) (U)=X.
יהי P(X=i)=p_i נגדיר את X ע"י: F(X-1)=∑_(i<X)▒p_i <u<∑_(i≤X)▒p_i =F(X)
לכן, P(X=i)=F(i)-F(i-1)=p_i
נציג כעת שיטה להתפלגות דיסקרטית
אלגוריתם היפוך ע"י חיפוש רציף:
	ייצר מספר אקראי U∈[0,1]
	X=0,S=p_(0 )
	כל עוד U>S תעשה
	X=X+1,S=S+p_(0 )
	תחזיר את X

-שיטת היפוך ע"י חיתוך של משתנה מקרי רציף-
בסעיף זה נתמקד במצבים בהם קשה למצוא את 〖,F〗^(-1) נמצא פונקציית עזר G ובעזרתה נייצר את הערכים האקראיים של x.
יהי G פונקציית התפלגות מצטברת בקטע [0,∞) כך שלכל i∈N:
 G(0)=0 ,G(i+1)=F(i)
נוכל לבנות אלגוריתם לבחירה אקראית של משתנה X ע"י הנוסחה:
x=⌊G^(-1) ┤ ├ (U)⌋
טכניקה זאת מהירה מאוד כאשר G^(-1) ידוע, יתר על כן לכל i≥0:
P(X≤i)=P(G^(-1) (U)<i+1)=P(U<G(i+1))=G(i+1)=F(i)
כלומר המשימה היא למצוא G כך ש: G(i+1)-G(i)=p_i לכל i.
לדוגמא התפלגות גיאומטרית
כאשר G(x)=1-e^(-λx) לכל x≥0.
G(i+1)-G(i)=e^(-λi)-e^(-λ(i+1) )=e^(-λi) (1-e^(-λ) )=(1-q) q^i
כאשר q=e^(-λ)  לכן  x=⌊-1/λ  log⁡(U) ⌋.

-היפוך מבוסס השוואה-
עד כה באלגוריתם של חיפוש בהשוואה (אלגוריתם היפוך ע"י חיפוש רציף) ההשוואה בין ערכי ההסתברויות של p_i המצטברים התבצעה בצורת חיפוש לינארית וראינו שהחיפוש היה יעיל ומהיר, נרצה למצוא שיטה יעילה אף יותר להשוואה סדרתית משופרת שתמקסם את מהירות החיפוש. נעיר כי חיפושים מבוססי השוואה הם המוטיבציה לדיון בשיטת Alias שכן Alias מספק אלגוריתם להיפוך תוך איטרציה בודדת.
לצורך העניין נדרש לבניית עץ חיפוש בינארי זמן הריצה הוא O(log_2⁡〖n)〗  אשר מהיר יותר מחיפוש לינארי ב O(n).
נדגיש כי בניית עץ תעבוד רק למקרים בהם מספר ההסתברויות סופי.
דוגמא - יהי הסתברויות: p_0=0.11,p_1=0.3,p_2=0.25,p_3=0.21,p_4=0.13
עץ חיפוש בינארי:





מספר ההשוואות עד להגעה לפתרון היא L=1+⌊log_2⁡〖2k+1〗 ⌋ כאשר 2k+1 מספר הצמתים בעץ.
אך למרות שיפור זמן הריצה למציאת x נרצה לשפר אף יותר לעץ אופטימלי לכן ניישם את השיטה של Huffman למציאת עץ חיפוש אופטימלי.





נדגים את השיטה ע"י הדוגמא הקודמת:







Huffman בונה עץ חיפוש בינארי על פי אלגוריתם שמצמיד זוגות של האיברים עם ההסתברות הנמוכה ביותר ברקורסיה. ההסתברות של צומת האב היא סכום ההסתברויות של הבנים שלו. התהליך חוזר על עצמו עד שיש רק צומת אחד.

-היפוך בעזרת טבלה-
ראינו ששיטת ההיפוך יכולה להיות מבוססת על עץ בינארי או אופטימיזציה של עץ בינארי בצורה כזו או אחרת שיטות השוואה הם בסיסיות למדי בתחום מדעי המחשב כעת ניגש לשיטות שלא עסקנו עד כה – Hashing Method הידועות זמן רב כמקור מהיר מאוד לחיפוש במודל נתונים. השיטה הוצגה לראשונה ע"י Chen and Asau בשנת 1974 כדי להתמודד עם היפוך, יתר על כן במשך נראה כי שיטת  Aliasהיא מקרה פרטי של שיטת ההיפוך בעזרת טבלה או יותר נכון בעזרת שני טבלאות במקביל כדי למקסם יעילות ולהחזיר x בהתפלגות נתונה תוך איטרציה בודדת, נציג ביתר פירוט בפרק הבא. 
כדי להבטיח זמן ריצה טוב הם בנו טבלה מנחה שמאיצה את מהירות החיפוש.
נזכיר כי יש לנו קשר מונוטוני בין X ל u ( uהמספר האקראי בקטע [0,1]).
יהי  p ̅=(p_0,…,p_k) וקטור ההסתברות, נגדיר סדרה q_i ע"י: q_i=∑_(j=0)^i▒p_i 
נדמה זריקה של חץ לקטע [0,1] (כלומר כמו להרגיל מספר u בקטע זה) שמחולק ל k+1 תתי קטעים כך [0,q_0 ),…,[q_(k-1),1] , זאת דרך נוספת לתאר את הבעיה שלנו.
נגדיר טבלת ערכים g ע"י:
g_i   max┬(q_i<i/(k+1))⁡〖(j)〗
אלגוריתם השיטה:
	ערך אקראי U∈[0,1]
	X=⌊(k+1)U+1⌋
	X=g_X+1
	כל עוד: q_(X-1)>U תעשה: X=X-1
	תחזיר את X

משפט 2.1 –
המספר הצפוי של השוואות בין U ל q_(X-1) תמיד חסום מלמעלה ע"י 2
הוכחה - ברור שמספר ההשוואות אינו גדול ממספר החלוקות של הקטע [0,1] ועוד אחד.
אבל מכיוון שכל התת קטעים שווים בגודל אז:
E(C)≤1+1/(K+1)∙∑_(i=0)^k▒〖(*)〗≤1+1=2
* מספר הערכים של q_i בתת קטע הi-

משפט 2.1 מבטיח ביצועים טובים מאוד לשיטה לכל ההתפלגויות כל עוד מוודאים כי מספר תת הקטעים בחלוקה של הקטע [0,1] שווה למספר הערכים האפשריים בהתפלגות דיסקרטית נתונה.
כאמור נצטרך g_1,…,g_(k-1) כטבלה מוכנה מראש שאותה ניצור בזמן ריצה O(k) ( = k מספר החלוקות של הקטע [0,1])

אלגוריתם ליצירת הטבלה:
לכל i∈N ,1≤i≤k+1  : g_i=0
S=0
לכל i∈N ,0≤i≤k  : 
     S=S+p_i
     j=⌊S∙(k+1)+1⌋
     g_i=i
לכל i∈N ,2≤i≤k+1  : g_i=max⁡(g_(i-1),g_i)

יש קשר ישיר בין מספר השוואות הצפוי לבין הגודל של הטבלה המנחה כלומר 
אם יש (k+1)∙α איברים (איזשהו α>0) בטבלה המנחה אז : E(C)≤1+1/α
אם זמן הריצה חשוב באופן חריג נוכל לקבוע α גדולה מאוד כמו: 5,10 ,השיטה הנוכחית מראה את הפוטנציאל האדיר בשיפור יעילות זמני ריצה של חיפושים שונים.

-היפוך ע"י תיקון-
פעמים רבות אפשרי למצוא פונקציה G שקרובה לפונקציה F (פונקציית הסתברות מצטברת)
G פונקציה למשתנה הרציף Y, F פונקציה למשתנה הרציף X.
נניח כי פונקציית ההסתברות מצטברת G נוחה יותר לחישוב מאשר F.
ונרצה כי: F(i)-F(i-1)≈G(i)-G(i-1)
אחרי שנמצא G כזאת נבצע תיקון קטן לY- ונקבל הערכה מספיק טובה לx-.
אלגוריתם התיקון בצורה הישירה: 
U∈[0,1]
, X=G^(-1) (U) G(X-1)<U≤G(X) לX -
אם U≤F(X) 
אז כל עוד U≤F(X-1) תעשה X=X-1
אחרת כל עוד U>F(X-1) תעשה X=X+1
תחזיר את הערך של X

משפט 2.2 -
מספר השוואות של הפונקציה F עד להחזרת ערך X הוא: E(C)=|Y-X|
כאשר X,Y: F(X-1)<u≤F(X),G(Y-1)<u≤G(Y)

אלגוריתם תיקון: (בהינתן F≤G) 
U∈[0,1]
X=G^(-1) (U)
כל עוד U>F(X) תעשה X=X+1
תחזיר את הערך של X

חסכנו באלגוריתם האחרון את מספר ההשוואות לבדיקה האם הערך של X מתחת או מעל F^(-1) (U).
ממשפט 2.2 אנו למדים כי אם Y≤X אז E(C)=1+E(X-Y) 
כלומר E(C)=1+E(X)-E(Y) 
יתר על כן, ידוע כי: E(X)=∑_i▒(1-F(i)) , E(Y)=∑_i▒〖(1-G(i))  〗,
לכן נוכל לכתוב את E(C)  בצורה: E(C)=∑_i▒〖|F(i)-G(i)| 〗
לעיתים נרצה לייצר את הצמד משתנים אקראיים (u ,x) בצורה לא ישירה


אלגוריתם התיקון בצורה הלא ישירה: 
,V∈[0,1] ניצור מספר x אקראי ב [0,1] של הפונקציה G
U=G(X-1)+V(G(X)-G(X-1))
אם U≤F(X) 
אז כל עוד U≤F(X-1) תעשה X=X-1
אחרת כל עוד U>F(X-1) תעשה X=X+1
תחזיר את הערך של X

קל לראות כי שני השיטות הישירה והלא ישירה שוות מכיוון שהפונקציות הסתברות מצטברת זהות בצמד המשתנים (U ,X), יתר על כן בשני המקרים יש אותו יחס מונוטוני בין המשתנה הרציף X לבין U.



















פרק 4 שיטת Alias
4.1 הקדמה
נחפש מבנה נתונים היעיל ביותר להדמיית הטלה של קובייה הגונה\אינה הגונה.
למה זה חשוב? הדמיה של קובייה יכולה לעזור בין היתר למצוא אסטרטגיה אופטימלית במשחקי מזל כמו רולטה,Crabs.
מחוץ לתחום המשחקים ניתן למשל להשתמש במבנה נתונים בתחום הרובוטיקה ביודענו על הסתברות הסטייה של חיישן מערך האמת שלו לדוגמא: קיים חיישן המודד את הטמפרטורה של הסביבה וההסתברות היא 95% להצלחה במדידה, 4% למדידה נמוכה מערך האמת , 1% למדידה גבוהה מערך האמת, נוכל להיעזר בהסתברות אלו כדי לדייק עוד יותר נתון שרירותי שהגיע מהחיישן תוך התחשבות בסטייה שלו.
הפתרון לבעיה מצביע על טכניקה רבת עוצמה, תחת הנחות כלשהן על המודל נוכל למצוא סימולציה של קובייה בסיבוכיות זמן ריצה  O(1)עד כה ראינו כמה סוגים של אלגוריתמים למציאת ערך אקראי נשים לב כי עד כה לא הצלחנו להבטיח כי זמן הריצה של האלגוריתם יהיה כחיפוש אחד בודד בתוך המודל במקרה הכי טוב בשיטת ההיפוך נעזרנו במודל העצים הבינאריים כדי לייעל את האלגוריתמים עד כדי O(log_2 (n))

4.2 טרמינולוגיה ומושגים
קובייה שאינה הוגנת - קובייה שבה ההתפלגות לבחירת כל אחד מ- 6 הפאות של הקובייה יהיה שונה כלומר התפלגות דיסקרטית.
פעולות חיבור, חיסור, כפל, חילוק והשוואת גדלים של איברים ממשיים - כמובן כדי לחשב הסתברויות נצטרך להיות מסוגלים להשתמש בכל סל הפעולות האלו, לשם התעסקות בפיתוח האלגוריתם נאלץ להזניח במעט נימוקים ודיוק אריתמטיקה.
הגרלת מספר ממשי בטווח  (0,1] - בעסקנו בהסתברות נצטרך מעת לעת להיעזר במקור הגרלה של מספר בטווח הנ"ל.
חישוב ערך תחתון של מספר ממשי - חישוב של ערך כזה במחשב יכולה להיות משימה לא כל כך פשוטה, אך גם כאן נזניח את הקושי כמובן שנוכל לאחר ביניית האלגוריתם לרדת לסוגיות כאלו ולדבר על בנייה וייעול של אלגוריתם מהסוג של פונקציית ערך תחתון, חשוב להדגיש ברוב שפות התכנות לדוגמה Python בתוך מחלקת NumPy יש פונקציית ערך תחתון מובנת.






4.3 הדמיית קובייה הגונה
 לפני שניצור הדמיות מורכבים יותר בהמשך המאמר נצטרך מודל פשוט יעיל ואלגנטי כמו שנציג כאן שבו נעזר כעמוד תומך כמעט לכל הדמיה.
הרעיון מאחורי האלגוריתם:
יהי קובייה עם n-צדדים, נדמה את הקובייה לקטע (0,1]  נחלק את הקטע לn תת קטעים שווים כמספר צדדי הקובייה (אורך כל תת קטע הוא 1/n).
לדוגמא קובייה עם 4 צדדים-
 

 נגריל מספר  xבקטע (0,1] כך שהמספר יכנס לאחד מהתת קטעים של הישר (0,1]
לדוגמא הוגרל x=0.6 -
 
קל לראות שהצד שהוגרל הוא כמובן 2 אבל איך נתאר את זה בצורה מתמטית ע"י נוסחה שנוכל להשתמש בה באלגוריתם, התשובה פשוטה למדיי מכיוון שהקובייה הגונה כל התת קטעים של הישר (0,1] שווים בדיוק 1/n לכן נוכל לבדוק האם  i/n≤x  שזה שקול ל מציאת מקסימום של n כך ש i≤xn  שזה בהגדרה i=⌊xn⌋   כעת שיש לנו את כל הכלים המתמטיים וניגש לבניית האלגוריתם,
אלגוריתם(Pseudo-code): הדמיית קובייה הגונה
	הגרלת ערך בקטע x∈(0,1]
	להחזיר ⌊xn⌋
סיבוכיות זמן ריצה – O(1)

4.4 הדמיית קובייה לא הגונה בעזרת קובייה הגונה
 כאשר נתון אלגוריתם לקובייה הגונה נשאלת השאלה האם ניתן לעבור לקובייה שאינה הגונה? התשובה היא כן.
קודם כל נקבל את ההסתברויות p_0,…,p_(n-1) (נסמנם ב p ̅   ) שמייצגות את הסיכוי ליפול על כל אחד מ-n הצדדים של הקובייה. 
נמצא כפולה משותפת מינימלית (LCM) של מכני השברים של p ̅ מספר זה יהווה את מספר התת קטעים השווים שנחלק את הקטע (0,1] וכל הסתברות p_i תקבל "באופן יחסי" חלק בקטע.

ניגש ישירות לדוגמא פשוטה: יהי קובייה לא הגונה עם הסתברויות 1/2,1/3,1/12,1/12 לכן הLCM של המכנים הוא 12, נחלק את הקטע [0,1) ל12 קטעים שווים כך:

נסמן כל צד של הקובייה הלא הוגנת בצבע אחר (לצד ה-i נסמן 〖L∙p〗_i תת קטעים של הישר):

 כעת שנגריל אחר בקטע הוא "ייפול" לתוך אחד מ12 הקטעים הללו ובכך נדע בדיוק לאיזה צד של הקובייה הוא מתאים, 
ניגש לבניית האלגוריתם
אלגוריתם(Pseudo-code): הדמיית קובייה לא הגונה בעזרת קובייה הגונה
אתחול:
	נמצא LCM  של מכני השברים של  p ̅ נציבו כ- L 
	ניצור מערך A בגודל L
	לכל i∈N ,0≤i≤n-1 ,נציב i ב- 〖 L∙p〗_iהמקומות הבאים
יצירה:
נריץ את האלגוריתם להדמיית קובייה הגונה לL- צדדים ונקבל את הצד S ונחזיר A[S]
טבלת סיבוכיות זמן ריצה
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע

קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)
O(1)	O(n)	O(∏_(i=0)^n▒di)

* di המכנה של ההסתברות הp_i  (מעתה לא נעיר יותר שזאת הכוונה)
הערה: נעיר כי האלגוריתם אינו מתאים למקרים בהם ההסתברות אינה מוצגת כמספר רציונלי לדוגמא אם יש הסתברות 0.25 ו0.2500000001 לא נשתמש בשיטה שהצגנו כאן.

4.5 הדמיית מטבע מוטה
 באופן אינטואיטיבי להגדרת הדמיית קובייה הגונה נגדיר הדמייה של מטבע מוטה.
אלגוריתם(Pseudo-code): הדמיית מטבע מוטה (ההסתברות שיצא פלי היא p)
	הגרלת ערך x בתחום [0,1)
	אם x<p תחזיר פלי
	אם x≥p תחזיר עץ
סיבוכיות זמן ריצה - O(1)

4.6 הדמיית קובייה הגונה בעזרת מטבע מוטה
 מהדיון הקודם ראינו כי ניתן ליצור הדמיה של קובייה לא הגונה עם קובייה הגונה השאלה המתבקשת היא האם נוכל לייצר הדמיה קובייה לא הגונה בעזרת מטבע מוטה, התשובה היא כן.
הדרך להדמיית מטבע מוטה היא חלוקת הקטע [0,1) לשני תת קטעים האחד "פלי" והשני "עץ"
נציג כעת את האלגוריתם ליצירת ההדמיה כאשר i הוא צד של הקובייה 
אלגוריתם(Pseudo-code): הדמיית קובייה הגונה בעזרת מטבע מוטה
	לכל i∈N ,0≤i≤n-1  :
	לזרוק מטבע מוטה עם הסתברות 1/(n-i) לקבלת פלי
	אם נקבל פלי נחזיר i 

סיבוכיות זמן ריצה - O(n)
האם האלגוריתם באמת נכון ? כלומר נשאלת השאלה האם באמת ההסתברויות שיצא כל אחד מצדי הקובייה הוא בדיוק  1/n כאשר יש לקובייה ההגונה n צדדים.
משפט 3.1 - כל צד i של קובייה הגונה ההסתברות שלו היא בדיוק 1/n
הוכחה - נוכיח את המשפט בעזרת אינדוקציה שלמה:
בסיס האינדוקציה – כאשר i=0 יש הסתברות של  1/(n-0)=1/n  לצד ה-0 לצאת בקובייה.
נניח כי עבור 0,…,k-1 ההסתברויות של כל אחד מהם הוא בדיוק 1/n.
נוכיח כי הצד ה-k  יצא בהסתברות של 1/n.
לצד ה-k  יש הסתברות  1/(n-k)  לצאת, עד לצד ה-k  ההסתברות שלא נקבל פלי בשום שלב הוא בדיוק k/n לכן ההסתברות שנגיע לצד ה-k  הוא  1-k/n המכנה המשותף הוא n לכן נקבל (n-k)/n   כלומר כדי שנגיע לצד ה-k  ובו נקבל בהטלה של המטבע פלי ההסתברות היא:
 1/n=1/(n-k)∙(n-k)/n כלומר הוכחנו כי ההסתברות של צד k בדיוק 1/n  ע"י אינדוקציה שלמה.

4.7 הדמיית קובייה לא הגונה בעזרת מטבע מוטה
נתאר ישירות את האלגוריתם במידה והקורא לא הבין אל דאגה נצרף דוגמא בהמשך.
האלגוריתם(Pseudo-code): הדמיית קובייה לא הגונה בעזרת מטבע מוטה
אתחול:
	נשמור את p_0,…,p_(n-1)  ההסתברויות לשימוש עתידי (ההסתברות p_i מתאימה לצד הi-)
יצירה:
נגדיר משתנה מאתחל ל 1 נקרא לו mass
	לכל i∈N ,0≤i≤n-1  :
	נטיל מטבע מוטה בהסתברות של (p_i  )/mass  לפלי
	אם יצא פלי נחזיר את i
	אחרת תעדכן mass = mass – p_i

סיבוכיות זמן ריצה - O(n)
ניגש ישירות לדוגמא
יהי קובייה כך שהסתברויות של צדדי הקובייה הן: 1/2,1/3,1/12,1/12.
לכן הקטע [0,1) יחולק באופן הבא - 


- נטיל מטבע מוטה בהסתברות 1/2 שיצא פלי (במידה ויצא פלי נבחר צד 0 במידה ולא נעבור לשלב הבא)
- נטיל מטבע מוטה בהסתברות 2/3 שיצא פלי (במידה ויצא פלי נבחר צד 1 במידה ולא נעבור לשלב הבא)
- נטיל מטבע מוטה בהסתברות 1/2 שיצא פלי (במידה ויצא פלי נבחר צד 2 במידה ולא נעבור לשלב הבא)
- נטיל מטבע מוטה בהסתברות 1 שיצא פלי (יצא פלי נבחר צד 3)




השוואה בזמני ריצה ביחס לאלגוריתם הקודם:
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע
קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)	O(1)	O(n)	O(∏_(i=0)^n▒di)
קובייה לא הגונה בעזרת זריקת מטבע מוטה	O(n)	O(1)	O(n)	O(n)

נבדוק את נכונות האלגוריתם, כלומר נשאל האם ההסתברות של כל אחד מצדי הקובייה הלא הגונה היא בדיוק p_0,…,p_(n-1)  בהתאמה.

משפט 3.2 - כל צד i של קובייה הלא הגונה ההסתברות שלו לצאת היא בדיוק p_i
הוכחה - נוכיח את המשפט בעזרת אינדוקציה שלמה:
בסיס האינדוקציה – כאשר i=0 יש הסתברות של  p_i לצד ה-0 לצאת בקובייה, באלגוריתם ההסתברות היא p_i/mass כאשר mass בדיוק 1 לכן ההסתברות היא p_i כנדרש.
נניח כי עבור 0,…,k-1 ההסתברויות של כל אחד מהם היא בדיוק p_0,…,p_(k-1) בהתאמה.
נוכיח כי הצד ה-k  יצא בהסתברות של p_k.
הצד הK- יבחר כאשר הk-1-  צדדים הראשונים לא יבחרו כלומר לפי האלגוריתם בהסתברות של  ∑_(i=0)^(k-1)▒p_i   כלומר ההסתברות שנגיע לצד ה :k- 1-∑_(i=0)^(k-1)▒p_i   וההסתברות שנבחר את הצד הk- היא  p_k/mass לכן לסיכום ההסתברות שניפול על הצד הk- היא בדיוק כפל ההסתברויות:
(1-∑_(i=0)^(k-1)▒〖p_i)∙〗  p_k/(1-∑_(i=0)^(k-1)▒p_i )=p_k

לכן הוכחנו באינדוקציה שלמה שהצד הi- יצא בדיוק בהסתברות של p_i.

אנו יכולים לתאר בדיוק ובאופן מתמטי את מספר ההטלות הצפויות של זריקת מטבע עבור אלגוריתם זה. נחשוב על משתנה כלשהו X המייצג את מספר הזריקות של מטבע בכל ביצוע של האלגוריתם. כלומר, P[X=1] הוא ההסתברות שהאלגוריתם יזרוק רק מטבע אחד לפני שיסיים, P[X=2] הוא ההסתברות שהאלגוריתם יזרוק שני מטבעות בלבד, וכן הלאה. במקרה זה, מספר הזריקות הצפויות עבור האלגוריתם שלנו מתקבל יסומן ב- E[x] (בקורס תורת ההסתברות 20425 E[x] נקרא תוחלת)

E[x]=∑_(i=1)^n▒〖i∙P[x=i] 〗=∑_(i=1)^n▒〖i∙p_(i-1)=〗
=∑_(i=1)^n▒〖((i-1) p_(i-1)+p_(i-1) )=〗 ∑_(i=1)^n▒〖(i-1)∙p_(i-1)+∑_(i=1)^n▒p_(i-1) 〗

בשווין האחרון הביטוי הימני שווה ל ∑_(i=0)^(n-1)▒〖i∙p_i 〗=E[P]    הביטוי השמאלי שווה ל1 כסכום ההסתברויות יחדיו לכן נקבל את הנוסחה השימושית הבאה:
E[x]=E[P]+1
כלומר מספר הפעמים של זריקת המטבע הצפוי הוא אחד ועוד המספר של הצד הi- הצפוי לצאת בהטלה הנוכחית.

4.8 הכללת מטבע מוטה להדמיית קובייה לא הגונה
 בהדמיה הקודמת ראינו עד כמה יעילה ההדמיה תחת מטבע מוטה אבל נשאלת השאלה האם ניתן להיות יעילים יותר מה קורה כאשר יש מספר גדול של צדדים לקובייה
נציג כאן שיטה אחת מיני רבים ליעילות של ההדמיה, נפתח בדוגמא:
יהי קובייה לא הגונה עם הסתברויות של צדדי  1/4,1/5,1/8,1/8,1/10,1/10,1/10   בהתאמה, אם נחלק את הקטע (0,1] לשבע חלקים זה יראה בדיוק כך:

נגריל ערך x בקטע (0,1] והשאלה העומדת לדיון היא איך נמצא את התת קטע שבו נמצא x בצורה המהירה ביותר ?, לשאלה זאת נציג שתי תשובות סטנדרטיות:
הדרך הראשונה למצוא את התת קטע הרצוי היא חיפוש לינארי כלומר נתחיל מהתת קטע הראשון מימין ונשאל את עצמנו האם X שייך לקטע במידה ולא נעבור לתת קטע הבא משמאלו וכן אלה עד שנמצא את הקטע בוא x נמצא.
נדגים – נגריל ערך x=27/40 ונחפש את התת קטע המתאים ע"י חיפוש לינארי,

זמן הריצה הוא O(n)
הדרך השנייה ראינו בפרק 2 איך בניית עץ בינארי לבעיה יכול להועיל בזמן החיפוש לכן ניישם גם כאן חיפוש בינארי בקטע (0,1] ,אלגוריתם חיפוש כזה שמבוסס על רעיון החלוקה והחצייה, בחיפוש בינארי בכל שלב מתבצע חיתוך הקטע לשניים והבדיקה מתבצעת רק בחצי מהקטע, מה שמפשט את החיפוש ומפחית את מספר האפשרויות.
זמן הריצה של חיפוש בינארי הוא O(log_2⁡〖n)〗 בשונה מחיפוש לינארי.
נדגים – נגריל ערך x=39/40 ונחפש את התת קטע המתאים ע"י חיפוש בינארי,
 







האלגוריתם(Pseudo-code): "בחירת גלגל הרולטה"
אתחול: 
	ניצור מערך A בגודל n
	נציב A[0] = p0
	לכל i∈N ,0≤i≤n-1  :
	     A[i]=A[i-1]+p_i
יצירה:
	נגריל ערך x בקטע [0,1)
	נפעיל אלגוריתם לחיפוש בינארי – נמצא את הצד הi- הקטן ביותר כך ש x גדול ממנו
	נחזיר את הערך i
סיבוכיות זמן ריצה
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע
קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)	O(1)	O(n)	O(∏_(i=0)^n▒di)
קובייה לא הגונה בעזרת זריקת מטבע מוטה	O(n)	O(1)	O(n)	O(n)
בחירת גלגל הרולטה	O(n)	O(log_2⁡〖n)〗	O(n)

דיי ברור שכעת יש לנו אלגוריתם הרבה יותר יעיל במקרה הגרוע מההדמיה בסעיף הקודם.
זה ברור שכעת יש לנו אלגוריתם הרבה יותר טוב מאשר האלגוריתם הראשון. הגישה החדשה על פי ערך הדומיננטי וחיפוש בינארי נראית כמהימנה הרבה יותר. עם זאת, עדיין יתכנו שדרוגים בגבולות אלו באמצעות קבוצה חכמה של טכניקות היברידיות, כפי שנראה בעוד רגע.
אלגוריתם גלגל הרולטה האופטימלי:
מסתבר שחיפוש בינארי בעץ (BST) יעיל אף יותר נראה זאת בדוגמה ממקודם,
לדוגמא: יהי קובייה שאינה הגונה עם הסתברויות 99/100,1/600,1/600,1/600,1/600,1/600,1/600
במקרה זה הסיכוי שיצא צד אחד של הקובייה מוטה באופן קיצוני למדיי, נבנה עץ חיפוש בינארי להדמיה,

בעוד שהעץ הבינארי הנ"ל מאוזן, זה לא עץ טוב לחיפוש בינארי לבעיה שלנו.
מכיוון שאנו יודעים כי מכל 100 הגרלות 99 פעמים מהם ילכו לתת הקטע (0,99/100] אז נרצה שהצומת עבור התת קטע הגדול יובדל לבדיקה ראשונה. היתרון בשינוי העץ גובר על הקנס מהמקרים הנותרים.

דיון תיאורטי: נתונה קבוצת ההסתברויות נרצה למצוא את עץ החיפוש הבינארי המינימלי של ההסתברויות אשר ממזער את זמן החיפוש המצופה. ידוע לנו שבעיה נחקרה היטב במדעי המחשב ונקראת עץ החיפוש הבינארי האופטימלי. קיימים הרבה אלגוריתמים לפתרון הבעיה לדוגמא העץ של Huffman מפרק 2. ידוע שניתן למצוא פתרון מדויק בזמן O(n^2) באמצעות תכנות דינמי, וישנם אלגוריתמים ליניאריים טובים המצליחים למצוא פתרונות טובים.
ההתנהגות של האלגוריתמים לחיפוש בעצי חיפוש בינאריים אופטימליים היא הטובה ביותר כאשר ההתפלגות ההסתברויות אי-מאוזנת דרסטית, מאחר שניתן להעביר את הצמתים שמכילים את רוב מסת ההסתברות לסמוך לשורש של העץ, וההתנהגות הגרועה ביותר היא כאשר ההתפלגות ההסתברויות מאוזנת, שכך העץ יהיה רחב ושטוח.

לסיכום נציג את כלל ההדמיות וזמן הריצה שלהם בכל אחת מהחלקים:
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע
קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)	O(1)	O(n)	O(∏_(i=0)^n▒di)
קובייה לא הגונה בעזרת זריקת מטבע מוטה	O(n)	O(1)	O(n)	O(n)
בחירת גלגל הרולטה	O(n)	O(log_2⁡〖n)〗	O(n)
בחירת גלגל הרולטה אופטימלי	O(n^2)	O(1)	O(log_2⁡〖n)〗	O(n)


4.9 הדמיית קובייה לא הגונה בעזרת מטבע מוטה וקובייה הגונה
 עד כה ראינו איך בעזרת מטבע מוטה וקובייה הגונה הצלחנו ליצור הדמיה לקובייה שאינה הגונה.
האם יש הדמיה שבה נוכל להתבסס גם על קובייה הגונה וגם על מטבע מוטה יחדיו ? , התשובה היא כן לא נתפלא כי הגישה החדשה שנציג זה עתה היא שילוב מוצלח של שני הגישות בסעיפים הקודמים.
עד כה תיארנו את הצדדים של הקובייה בממד אחד כלומר בקטע [0,1).
שני ההדמיות הקודמות עובדות על בחירה אקראית של מספר בקטע [0,1) ואחר כך למפות את הקטע. העיקרון המוביל היה ככל שההסתברות של צד מסווים יותר גבוה כך הצד יקבל חלק יחסי גדול יותר בקטע [0,1)  .
מה היה קורה אם היינו חושבים במקום בממד אחד בשני ממדים? או מה היה קורה אילולא היינו חושבים שההסתברות הpi- לא מוצגת כאורך אלה כשטח מתוך מלבן מסוים?
כדי לענות על שאלות אלו נחזור לדוגמה ישנה שעסקנו בה, יהיה קובייה לא הגונה עם הסתברויות 1/2,1/3,1/12,1/12 ,
יהי w>0 רוחב כל מלבן באיור
נחפש את השטח של כל המלבנים יחדיו:
∑_(i=0)^(n-1)▒〖wp_i=w∙∑_(i=0)^(n-1)▒〖p_i=1w〗〗

כעת נצייר מסגרת כמלבן אחד גדול שמכיל את כל הלבנים הקטנים כך:

רוחבו  W4 ואורכו 1/2.
נוכל להסתכל על המלבן הנ"ל כחלוקה ל5 אזורים שונים, 4 אזורים לייצוג הסתברויות השונות של צדי הקובייה ואזור אחד לא מנוצל.

במודל זה נוכל לחשוב על הדמיה של קובייה כזריקת חצים למלבן:
	אם פגע באזור לא מנוצל נזרוק שוב
	אם פגע באחד מהמלבנים שמייצגים הסתברויות של צדי הקובייה נחזיר את צד הקובייה, מכיוון שההסתברות גובהה יותר מקבלת שטח גדול יותר הסיכוי שנפגע עם החץ במלבן שמייצג אותו גבוה יותר
P[i במלבן לפגוע/המלבנים באחד לפגוע]=  (i המלבן שטח )/(המלבנים כל שטח )=(wp_i)/w=p_i
במילים אחרות מצאנו דרך חדשה לתאר זריקת קובייה.
השאלה המתבקשת היא איך נדמה זריקה של חץ למלבן ?
תשובה אחת היא לדמות בחירה אקראית של שני ערכים בין [0,1) לתיאור האורך והרוחב של הפגיעה במלבן, אבל שיטה זאת תחזיר אותנו לגישה הקודמת של בדיקת איזה מלבן פגענו ע"י חיפוש לינארי/בינארי כך לא התרחקנו יותר מיד מההדמיה הקודמת לכן נבחר בשיטה אחרת:
נשים לב שהרוחב w יכול להיבחר איך שנרצה כל עוד יש לכל המלבנים את אותו רוחב.
האורך כצפוי מתבסס על ההסתברויות השונות של צדי הקובייה הלא הגונה, נוכל לבחור כופל סקלרי חיובי משותף לכל האורכים של המלבנים נסמנו בh .
לכן שטח המלבן החדש הוא:
∑_(i=0)^(n-1)▒〖whp_i=wh∙∑_(i=0)^(n-1)▒〖p_i=wh〗〗
יתר על כן לא השתנתה ההסתברות לבחירת צד מסוים,
P[i במלבן לפגוע/המלבנים באחד לפגוע]=  (i המלבן שטח )/(המלבנים כל שטח )=(whp_i)/wh=p_i
כיוון שנוכל לבחור איזה h>0 נרצה נבחר את האורך של המלבן הגדול ביותר של צד הi- להיות 1 כלומר נציב  h=1/p_i   יתר על כן, נציב w=1 נקבל:

כעת יש לנו את כל הכלים הדרושים כדי לחזור לשאלה איך נזרוק חץ בצורה אקראית בתוך המלבן.
נחלק את השטח הלא מנוצל למלבנים קטנים באופן הבא,

ניגש לתיאור הזריקה: לחץ יש ייצוג כזוג סדור (x,y) כך ש x∈[0,1) כלומר בחירת הצד של הקובייה ו y∈[0,1) שמייצג את האורך שנבחר כלומר האם נבחר את הצד או נטיל שוב.
אבל רק רגע זה בדיוק מה שחיפשנו, הטלת קובייה לא הגונה כתיאור של הטלת קובייה הגונה וזריקת מטבע מוטה!
במציאות, ניתן לראות בתוצאה הזו כמשהו עוצמתי יותר. כדי לדמות קובייה לא הגונה, אנו בונים סט של מטבעות מוטים (בהסתברות p_i/( p_max ) שיצא פלי ו( p_max-p_i)/( p_max ) שיצא עץ לצד הi-), אחד לכל צד של הקובייה, ואז משליכים קובייה הוגנת כדי לקבוע איזה מטבע להשליך. בהתבסס על הקובייה, אם יצא במטבע המתאים פלי, אנו בוררים את הצד הנתון, ואם יצא עץ, אנו משליך את הקובייה שוב וחוזרים לבצע את התהליך שוב.
נציג את האלגוריתם,
האלגוריתם (Pseudo-code): הדמיית קובייה לא הגונה בעזרת מטבע מוטה וקובייה הגונה
אתחול:
	נמצא את ההסתברות המקסימלית נסמנה ב  p_max
	בניית מערך בשם 'מטבעות' באורך n כמספר צדי הקובייה
	לכל i∈N ,0≤i≤n-1   :
	תציב במערך 'מטבעות' במקום הi- את p_i/( p_max )
יצירה:
	עד שלא נמצא ערך בצע צעדים 1-3:
	הטל קובייה הגונה עם n צדדים והחזר את הצד הi- שיצא
	זרוק מטבע מוטה כאשר הסתברות לפלי היא המקום הi- במערך 'מטבעות'
	אם יצא פלי תחזיר את i

סיבוכיות זמן ריצה
ננתח את זמן הריצה: למציאת ההסתברות המקסימלית נצטרך O(n) ולהגדרת המערך 'מטבעות' נצטרך עוד O(n) עד כה זמן הריצה הוא O(n).
צעד היצירה - המקרה הכי טוב הוא שבזריקה הראשונה של מטבע נקבל פלי לכן O(1)
במקרה הגרוע נרצה לצפות כמה נצטרך לזרוק מטבע מכיוון שידוע כי ההסתברות לבחור בצד הi- היא p_i/( p_max ) ובנוסף ההסתברות לבחור בצד הi- היא בדיוק 1/n לכן סכום ההסתברויות שצד מסוים יצא אחרי חזרה אחת,
∑_(i=0)^(n-1)▒〖(1/n∙p_i/p_max )=1/n ∑_(i=0)^(n-1)▒〖p_i/p_max =1/(n∙p_max ) ∑_(i=0)^(n-1)▒〖pi=1/(n∙p_max )〗〗〗
אם זאת ההסתברות שמטבע כלשהו יבחר באיטרציה אחת אז המספר הצפוי של איטרציות עד לקבלת צד הוא ההופכי של השבר כלומר p_max∙n , אבל מה זה בעצם אומר? מספר האיטרציות תלוי בבחירת p_max בלבד!
נסתכל על מקרה קיצון אחד, כאשר p_max=1 הקובייה תמיד תצא על אותו צד בכל פעם במקרה זה, המספר הצפוי של הפעמים הוא שווה n והוא אומר שמצפים לזרוק את הקובייה ההגונה  n פעמים. זה נראה סביר, מאחר והדרך היחידה שבה נבחר צד היא אם אנו בוחרים את המטבע המוטה לצד שתמיד יוצא פלי, מאחר וכל צד אחר של הקובייה יש לו מטבע שלא יוצא אף פעם פלי.
מקרה קיצון שני, נבחר את  p_max=1/n  אם הוא נמוך יותר מ1/n, הסכום הכולל של כל הצדדים יהיה פחות מ-1. המספר הצפוי של איטרציות הוא 1. זה גם סביר, מאחר ובמקרה זה, לכל צד יש אותה הסתברות להיבחר בדיוק 1 ההסתברויות של כל צד לצאת הוא 1, כל צד יהיה עם הסתברות 1 להיבחר. כלומר, זריקת הקובייה כדי לבחור את המטבע להטלה תהיה פעולה קבועה, מאחר והמטבע יצא תמיד פלי לא יהיה עלינו לחזור על התהליך.
אם לא השתכנעו מספיק למה מספר האיטרציות תלוי אך ורק ב  Pmaxנחזור לתיאור גיאומטרי, שטח המלבן שבו אנו זורקים חץ הוא תמיד n מאחר ואנו מסדרים את אורך שלו להיות 1. יתרה מכך, השטח הכולל של המלבנים המייצגים תשובות "כן" ניתן על ידי 1/p_max  מאחר וכל מלבן יש לו רוחב 1 ואורך המתאים בכפל ב1/p_max  . זה אומר שהיחס בין שטח המלבנים של תשובות "כן" לשטח הכולל של המלבן הוא  1/(n∙p_max ). כלומר, המרחב המושרה על ידי המלבנים של "לא" תלוי כולו בערך של  p_max.
נסתכל על טבלת זמני הריצה עד כה:
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע
קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)	O(1)	O(n)	O(∏_(i=0)^n▒di)
קובייה לא הגונה בעזרת זריקת מטבע מוטה	O(n)	O(1)	O(n)	O(n)
בחירת גלגל הרולטה	O(n)	O(log_2⁡〖n)〗	O(n)
בחירת גלגל הרולטה אופטימלי	O(n^2)	O(1)	O(log_2⁡〖n)〗	O(n)
הדמיית קובייה לא הגונה בעזרת מטבע מוטה וקובייה הגונה	O(n)	O(1)	O(n)	O(n)

במקרה הכי טוב ההדמיה הנוכחית יעילה יותר מהדמיה עם חיפוש בינארי ובמקרה הגרוע המצב רק חמור יותר וזמן הריצה גדל אקספוננציאלית.
4.10 שיטת Alias
נחפש שיטה שבה למלבן לא יהיה אזורים לא מנוצלים וכך שבזריקה אחת בודדת נקבל תשובה כלומר O(1) זמן ריצה.
השם אליס מגיע מהשם אליס ובוב דמויות מיתולוגיות שנהגו להיות תקועות בפינות המסתוריות של ספרי הקוד של שנות ה-2000.
לדוגמא נוכל להציב את הh  המנרמל של כל אחד מאורכי ההסתברויות להיות הממוצע של כלל ההסתברויות ולא ההסתברות המקסימלית כמו שעשינו בסעיף קודם.
נחזור לדוגמה מסעיף קודם כך  שההסתברויות הן 1/2,1/3,1/12,1/12 לך הממוצע שלהן הוא 1/4
ולאחר נרמול של הערך 1/4

כעת נשלים נתחום את המלבן שנגמר בהסתברות בגובה 1,

ניקח את החתיכות של ההסתברויות שלא נכנסו לתוך המלבן ונשלים אותן למקומות הלא מנוצלים של המלבן,

נוצרו 7 מלבנים כל מלבן מייצג צד מסוים של הקובייה.
כעת בשונה מאלגוריתם הקודם כשנטיל קובייה נבחר צד ונטיל את המטבע המתאים לו. אם ייצא פלי נבחר בצד אחד של הקובייה ואם יצא עץ לא נחזיר כמקודם לסבב נוסף אלה נבחר בצד השני של הקובייה בעמודה הרלוונטית.
אליס ברמה המופשטת:
דבר ראשון, ניצור מלבנים שמייצגים את ההסתברויות השונות של צדי הקובייה.
דבר שני, ננרמל את ההסתברויות ע"י כפל בהופכי של הממוצע שלהן לאחר מכאן נחתוך את המלבנים שלא נכנסו לגובה המתאים ואת החתיכות האלו נכניס לתוך המלבן שנוצר בשטחים הלא מנוצלים שלא.
לבסוף, נבצע הדמיה של זריקת חץ אקראי למלבן נוח לבצע זריקה כזאת כקומבינציה של הטלת קובייה הגונה וזריקת מטבע מוטה.
איך נדע שהפעולה של גזירת השטחים שלא נכנסו למלבן והדבקתן בשטחים הלא מנוצלים היא פעולה חוקית? לא רק שזה נכון אלה נוכל לעשות את זה ביותר מ2 צדדים לכל עמודה של המלבן הגדול.
החתיכות שהודבקו באופן מלאכותי מעל העמודות המקוריות נקראות לעיתים החלק האליאסי של העמודה ומכאן נולד השם של השיטה.

האלגוריתם(Pseudo-code): Alias
אתחול:
	ניצור מערכים בשמות Alias וprob
	ניצור עץ חיפוש T
	נכניס n∙p_i לתוך T לכל הסתברות i
	לכל j∈N ,0≤j≤n-1:
	תמצא ותוציא את הערך הקטן ביותר בעץ T נקרא לו p_l
	תמצא ותוציא את הערך הגדול ביותר בעץ T נקרא לו p_g
	prob[l]=p_i
	Alias[l]=g
	p_g □(∶=) p_g-(1-p∙l)
	נוסיף את p_g לעץ T
	ההסתברות האחרונה שנשארה היא i שגובהה צריך להיות 1
	prob[i]=1
יצירה:
	ניצור הדמיית קובייה הגונה והוגרל הצד הi-
	נטיל מטבע בהסתברות של prob[i] שיצא פלי
	אם יצא פלי תחזיר את i
	אחרת תחזיר את Alias[i]

סיבוכיות זמן ריצה
אלגוריתם	זמן אתחול	זמן יצירה	שימוש בזיכרון
	טוב	גרוע	טוב	גרוע	טוב	גרוע
קובייה לא הגונה בעזרת קובייה הגונה	O(n)	O(∏_(i=0)^n▒di)	O(1)	O(n)	O(∏_(i=0)^n▒di)
קובייה לא הגונה בעזרת זריקת מטבע מוטה	O(n)	O(1)	O(n)	O(n)
בחירת גלגל הרולטה	O(n)	O(log_2⁡〖n)〗	O(n)
בחירת גלגל הרולטה אופטימלי	O(n^2)	O(1)	O(log_2⁡〖n)〗	O(n)
הדמיית קובייה לא הגונה בעזרת מטבע מוטה וקובייה הגונה	O(n)	O(1)	O(n)	O(n)
שיטת Alias	O(nlog_2⁡〖n)〗	O(1)	O(1)	O(n)

לסיכום שיטת Alias היא מקרה פרטי של שיטת ההיפוך נראה זאת:
יהי f פונקציה שתתאר של ההתפלגות הדיסקרטית של המודל ע"י:
f(x)={█(p(x=0)=p_0@p(x=1)=p_1@p(x=2)=p_2@.@.@.@p(x=k-1)=p_(k-1) )┤
כאשר יש k קטגוריות שונות שאפשר ליפול בהן בהסתברויות p_0,…,p_(k-1) , אנחנו בהצגת שיטת Alias בחרנו להדגים את השיטה על התפלגות של קובייה מוטת בעלת k צדדים.
נוכל מ f לבנות פונקציית הסתברות מצטברת F  נגדיר ע"י:
F(x)=∑_(i≤x)▒p_i 
יתר על כן, F^(-1) מוגדר ע"י:
F^(-1) (u)=inf⁡{x∶F(x)=u ,0<u<1}
שיטת Alias נעזרת שתי טבלאות (Prob[],Alias[]) שבעזרתן השיטה קובעת את הערך האקראי על סמך  uערך אקראי בקטע [0,1] בלי לחשב את F^(-1) ישירות, זמן היצירה של השיטה כמו שראינו הוא O(1) מה שהופך אותה ליעילה מאוד. לסיכום הצגנו את שיטת Alias כמקרה פרטי של שיטת ההיפוך ע"י 2 טבלאות מנחות.

פרק 5 שיטת הדחייה
5.1 שיטת הדחייה להתפלגות רציפה
שיטת הדחייה מציעה רעיון פשוט למדיי להתעסקות עם התפלגויות זנב אינסופי או לחלופין התפלגויות משתנות באופן תדיר ששיטות אחרות שחקרנו עד כה לא מספקות תשובה בזמן סביר. שיטת הדחייה מבוססת על שני משפטים:
משפט 4.1:
יהי X∈R^d משתנה של פונקציית הצפיפות f, נגדיר משתנה מקרי אחיד U∈[0,1] 
לכן (X,c∙U∙f(X)) משתנה של התפלגות אחידה 
על A={(x,u):x∈R^d,0≤u≤c∙f(x)} כאשר c>0 נקרא קבוע הדחייה.
אם (X,U)∈A וקטור בעל התפלגות אחידה ב R^(d+1) אז נאמר כי X בעל פונקציית צפיפות  f.
(ניתן למצוא הוכחה של המשפט במקור מידע [2] עמוד 40)

משפט 4.2:
יהי x_1,…∈R^d וקטורים אקראיים, יהי A⊆R^d קבוצת בורל כך ש: P(x_1∈A)=p>0 נגדיר את y להיות הx_i הווקטורים הראשונים שלוקחים ערכים מA, אז ההתפלגות של y היא:
P(y∈B)=P(x_1∈A∩B)/p
(ניתן למצוא הוכחה של המשפט במקור מידע [2] עמוד 41)

האלגוריתם הבסיס של שיטת הדחייה, יהי g פונקציית צפיפות ו c≥1  קבוע הדחייה
 כך ש: f(X)≤c∙g(X) לכל X, אז X שההתפלגות שלו היא פונקציית הצפיפות f יתואר כך:
אלגוריתם הדחייה הבסיס: 
	נייצר משתנה X שההתפלגות שלו היא g
	נייצר U∈[0,1] משתנה בהתפלגות אחידה
	T=c∙(g(X))/(f(X))
	כל עוד U∙T>1 תחזור לצעד 1
	תחזיר את הערך X



לפי משפט 4.1 הוקטור (X,c∙U∙g(X)) בעל התפלגות אחידה מתחת לעקומה של
 u∙g(X) ב-R^(d+1). נוכל להסיק ממשפט 4.2 שהוקטור (X,c∙U∙g(X)) (שמיוצר ע"י האלגוריתם הבסיסי) הוא בהתפלגות אחידה גם מתחת לפונקציית הצפיפות f לכן שוב ממשפט 3.1 החלק השני X בעל התפלגות של פונקציית הצפיפות f.
שלוש עקרונות שנצטרך ליישם לפני שימוש בשיטת הדחייה:
	נצטרך למצוא פונקציית צפיפות g
	נרצה שיטה פשוטה יותר לייצור מספרים אקראיים בהתפלגות g
	נרצה לדעת מהו c
פעמים רבות נוכל להגדיר c∙g למחלקה של פונקציות צפיפות f, לא רק שנצטרך אלגוריתם פשוט לייצור אקראיות של g נצטרך לדאוג כי החישוב של (g(X))/(f(X)) קל ומהיר.
נסמן ב-N את מספר האיטרציות הדרושות למציאת x שמתפלג ע"י f, יש לנו:
P(N=i)=(1-p)^(i-1)∙p; P(N≥i) 〖=(1-p)〗^(i-1),i≥1 לכל
כך ש:
p=P(f(X)≥c∙U∙g(X))=∫▒〖P(U≤〗  (f(X))/(c∙g(X)))dX=∫▒〖(f(X))/(c∙g(X))∙g(X)dX=1/c ∫▒〖f(X)dX=1/c〗〗
כלומר מספר האיטרציות הדרוש מתפלג גיאומטרית עם הפרמטר 1/c זה טוב כי שההסתברות P(N=i) מונוטונית יורדת ובנוסף P(N>i)=(1-p)^i≤e^(-pi) יתר על כן,          E(N)=1/p=c כלומר נשאף כי מספר האיטרציות יהיה קטן ככול האפשר שכן נרצה c קטן ככול האפשר.
אלגוריתם לפונקציות צפיפות חסומות בעלות תומך קומפקטי: 
יהי C_(M,a,b) מחלקת פונקציות צפיפות כך שבקטע [a,b] הן חסומות ע"י M. נוכל לקבוע g(x)=(b-a)^(-1) לכל x∈[a,b], c=M(b-a).
 לכן אלגוריתם הדחייה למחלקה C_(M,a,b) נראה כך:
	נייצר U,V∈[0,1] משתנים בהתפלגות אחידה
	X=a+(b-a)∙V
	כל עוד U∙M>f(X) תחזור לצעד 1
	תחזיר את הערך X
נעיר כי האלגוריתם יכול להיות הרסני ובחירה קבועה של g למחלקת צפיפות יכולה להיות טובה רק במקרים ספציפיים מאוד !



נפתח אלגוריתם דחייה אופטימלי:
באופן כללי g נבחרת ממחלקה של פונקציות צפיפות פשוטות למדיי שכוללת את הצפיפות האחידה. כל שאר ההתפלגויות נוכל לייצר משיטת ההיפוך. יש 2 שיטות מרכזיות לבחירת g,c כך ש: f<cg. [1] נוכל ללמוד את התכונות של f ולהסיק מהן לגבי בחירת g,c אופטימליים, בעוד שלפעמים הגישה תעניק פתרונות מהירים היא יכולה להיות גרועה ותלויה המון ברקע המתמטי של המשתמש. [2] נתחיל במחלקה של פונקציות צפיפות g ונבחר g כך ש c הקטן ביותר. שיטה יעילה אבל לפעמים תוביל לבעיות אופטימיזציה.

אלגוריתם דחייה לפי פונקציית הצפיפות של לפלס: 
	נייצר X משתנה המתפלג מעריכית, V∈[-1,1] משתנה בהתפלגות אחידה
	כל עוד (X-1)^2>-2log⁡(|V|) תחזור לצעד 1
	תחזיר את הערך X=X∙sign(V) (הפונקציה sign מחזיר את הסימן של הקלט)

מציאת : c
לצפיפויות נתונות g,f קבוע הדחייה c צריך להיות לפחות שווה ל sup┬X⁡〖(f(X))/(g(X))〗.
בחירה כזו מבטיחה כי העקומה של f ו c∙g יגעו איפשהו במרחב.
לפעמים נרצה לקחת מחלקת צפיפויות g תלויה בפרמטר θ נסמנה g_θ ואז c_θ   (=sup)┬X⁡〖(f(X))/(g_θ (X))〗
 נרצה לבחור g_θ כך שc_θ קרוב מאוד ל-1.
לדוגמא משפחת הפונקציות של קושי g_θ (X)=θ/π∙1/(θ^2+X^2 ) נצטרך לבחור  c_θ:
c_θ={█(√2π/e^θ ∙e^(θ^2/2)             ,θ<√2@θ∙√(π/2)                  ,θ≥√2)┤
(ניתן למצוא הוכחה של c_θ במקור מידע [2] עמוד 46)
ומהדוגמא נגיע לאלגוריתם הדחייה המבוסס על פונקציית הצפיפות של קושי:
אתחול:
	α=√ⅇ/2
יצירה:
	נייצר  U,V∈[0,1] משתנים בהתפלגות אחידה
	X=tan⁡(π∙V),S=X^2 כעת x מתפלג ע"פ קושי
	כל עוד U>α∙(1+S)∙e^((-S)/2) תחזור לצעד 1
	תחזיר את הערך X
הכללה של שיטת הדחייה:
ישנם כמה הכללות של שיטת הדחייה חלקן מספיק טובות כדי שנציין אותן בפרק על שיטת הדחייה.
הכללה ראשון מתבססת על המקרה בו f מהצורה: f(X)=c∙g(X)∙ψ(X) כאשר לכל x מתקיים ψ(X)⊆[0,1] , g פונקציית צפיפות קלה יותר ו  c≥1 קבוע הדחייה המנרמל.
במקרה זה אלגוריתם הדחייה יראה כך: 
	נייצר  X בהתפלגות של g
	נייצר U∈[0,1] בעל התפלגות אחידה
	כל עוד U>ψ(X) תחזור לצעד 1
	תחזיר את הערך X

המתמטיקאי וודובה (1977) הציעה צורה יעילה יותר להציג את ψ כ: ψ=1-Ψ כאשר Ψ התפלגות פשוטה יותר.
אלגוריתם הדחייה של וודובה: 
	נייצר  X בהתפלגות של g
	נייצר  Y בהתפלגות של Ψ
	כל עוד X>Y תחזור לצעד 1
	תחזיר את הערך X
(למקרה בו ψ=Ψ  נצטרך להחליף את X>Y  ב X<Y   בצעד 3 של האלגוריתם)
משפט 4.3:
אלגוריתם הדחייה של וודובה לייצור משתנה אקראי בהתפלגות של פונקציית הצפיפות     f=c∙g∙ψ מספר האיטרציות הצפוי הוא c (קבוע הדחייה המנרמל).
(ניתן למצוא הוכחה של המשפט במקור מידע [2] עמוד 48)
יתר על כן המתמטיקאי לטך (Letac) הצליח למצוא כחלק מעבודת המחקר שלו חסם תחתון לכמות האיטרציות הצפויה לכל סוג של אלגוריתם דחייה. 

משפט 4.4:
נניח כי x=U_N משתנה אקראי מתפלג ע"פ פונקציית הצפיפות של f בקטע [0,1], כך שN  מספר האיטרציות של האלגוריתם הנתון ו u_i המשתנה האקראי שיוצר באיטרציה הi- לכן: 
E(N)≥|(|f|)|_∞      (|(|.|)|_∞ מייצג את הסופרמום של f [0,1])

 (ניתן למצוא הוכחה של המשפט במקור מידע [2] עמודים 49-50)


לשיטת הדחייה המקורית שמתבססת על אי השוויון f<cg , בכל איטרציה של אלגוריתם נצטרך לחשב את הערך (f(X))/(g(X)) ברוב המקרים החישוב יקר מעבודה הפשוטה שf  לרוב פונקציית מסובכת לחישוב ישיר לדוגמא כאשר f מוצגת במשוואה דיפרנציאלית רגילה או חלקית המצב יהיה מורכב למדי לחשב ישירות את (f(X))/(g(X)).
לכן נצטרך כלים חדשים לפתרון הבעיה. ההכללה שנייה מספקת את האלגוריתם להימנעות מחישוב ישיר של  (f(X))/(g(X)) . השיטה נקראת שיטת הדחיסה שמבוססת על האי שוויון: 
h_1 (X)≤f(X)≤h_2 (X)
כאשר  h_1,h_2 פונקציות צפיפות פשוטות יותר לחישוב.
נציג את אלגוריתם השיטה: 
	נייצר U∈[0,1] בעל התפלגות אחידה
	נייצר  X בהתפלגות של g
	W=U∙c∙g(X))
	תנאי=[W≤h_1 (X)] (ערך בוליאני)
	אם ~[תנאי] (כאשר ~ קשר השלילה) אז:
 1.אם W≤h_2 (X) אז: תנאי=[W≤f(X)]
     6. עד ש: (תנאי=אמת) תחזור שוב לצעד 1
     7. תחזיר את הערך x

האלגוריתם שהצגנו זה עתה משתמש במשתנה בוליאני [תנאי] כדי להימנע מיציאה מהלולאה שמוגדרת בצעד 6 של האלגוריתם.
(ישנם המון מקרים פרטיים של שיטת הדחיסה, נציג כאן אחד מהם את שאר השיטות תוכלו למצוא במקור במידע [2] עמודים 54-59)
דחיסה פרופורציונלית:
לפעמים נוכל להציג את החסימה של f ע"י אי השוויון: b∙g≤f≤c∙g כאשר g פונקציית צפיפות פשוטה יותר לחישוב מf- , b קבוע חיובי כך ש b וגם c קרובים מאוד לערך 1. דחיסה כזאת יכולה להיות מאוד יעילה נראה זאת ע"י האלגוריתם המתאים.
אלגוריתם הדחיסה הפרופורציונלית: 
	נייצר U∈[0,1] בעל התפלגות אחידה
	נייצר X בהתפלגות של g
	תנאי=[U≤b/c] (ערך בוליאני)
	אם ~[תנאי] (כאשר ~ קשר השלילה) אז:
1. תנאי=[U≤(f(X))/(c∙g(X))]
עד ש: (תנאי=אמת) תחזור שוב לצעד 1
     7. תחזיר את הערך x
באלגוריתם הנוכחי מספר החישובים של f הוא בדיוק c-b. האלגוריתם הנוכחי בד"כ מהווה שיטת בסיס לפיתוח אלגוריתם ליישום כללי, כלומר נחלק קטע שבו מוגדר המשתנה הרציף לתת קטעים שבהם פונקציית הצפיפות קבוע או כמעט צפיפות לינארית. למקרים כאלו נוכל לבחור בד"כg   מהצורה: g(x)=a_0+a_1∙x.
5.2 שיטת הדחייה להתפלגות דיסקרטית
שיטת הדחייה במקרה הדיסקרטי דומה לשיטת במקרה הרציף יתרונות השיטה כמו כן דומים נשתמש בשיטה כאשר ההתפלגות בעלת זנב אינסופי וגם שההתפלגות משנה בתדירות.
נתון כי ההסתברות ליפול לתוך הקטגוריה ה  i-היא p_i נגדיר הסתברות קלה יותר q_i כך ש: p_i≤〖c∙q〗_i לכל i≥0 ,כאשר c נקרא קבוע הדחייה.
נתאר את האלגוריתם: 
	נייצר מספר אקראי U∈[0,1] בהתפלגות אחידה
	ניצור X משתנה מקרי בדיד בהסתברות q_i, i≥0
	כל עוד U∙c∙q_X>p_X תחזור שוב לצעד 1
	תחזיר את הערך של X
מספר האיטרציות מתפלג גיאומטרית עם פרמטר 1/c. כל איטרציה נצטרך לחשב את p_X/(c∙q_X ) בדיוק כמו במקרה הרציף.

דוגמא יהי התפלגות דיסקרטית נתונה ע"י: p_i=6/(π^2∙i^2 ) מספר ההשוואות הצפוי עד למציאת x 
הוא 1+∑_(i=0)^∞▒〖i∙p_i=∞〗 אם נגדיר התפלגות קלה יותר q_i=1/(i(i+1))
לכן נוכל לבנות אלגוריתם מתאים כך שc- (קבוע הדחייה) האופטימלי הוא:
c=sup┬(i≥1)⁡〖p_i/q_i 〗=6/π^2 ∙sup┬(i≥1)⁡〖(i+1)/i〗=12/π^2 
	נייצר U,V∈[0,1] משנים אקראיים בהתפלגות אחידה
	X=⌊1/U⌋
	כל עוד 2VX>X+1 תחזור שוב לצעד 1
	תחזיר את הערך X

הסתברות מונוטונית יורדת: נוכל לייחס אלגוריתם ספציפי למקרה זה ברור כי לכל i : p_i≤1/i    האלגוריתם יראה כך: 
	נייצר משתנה אקראי X בהתפלגות פרופורציונלית לוקטור ההסתברות (1,1/2,…,1/n)
	נייצר U∈[0,1] מספר אקראי בהתפלגות אחידה
	כל עוד U>Xp_X תחזור שוב לצעד 1
	תחזיר את הערך X

מספר האיטרציות הצפויות: ∑_(i=1)^n▒1/i≤1 log_2⁡〖(n)〗.
לדוגמא להתפלגות בינומית בפרמטרים (p,n) הזמן הריצה הוא O(log_2⁡〖n)〗.
שיטת הדחייה ההיברידית: 
כאשר p_i≤c∙g(x) לכל i≥0 , x∈[i,i+1]
כאשר c≥1 הוא קבוע הדחייה.
 gפונקצית צפיפות ב [0,∞), את פונקצית הצפיפות f הרציפה למקוטעין 
נגדיר כך: f(x)=p_i לכל x∈[i,i+1].

אלגוריתם השיטה היברידית:
	Y משתנה אקראי מפונקציית הצפיפות של g
	X=⌊Y⌋
	נייצר מספר אקראי בהתפלגות אחידה U∈[0,1]
	כל עוד p_X<U∙c∙g(X) תחזור שוב לצעד 1
	תחזיר את הערך X

















פרק 6 אלגוריתם הזיגורט
6.1 תיאור השיטה
אלגוריתם הזיגורט מציג שיטה שמטרתה לייצר מספרים אקראיים מפונקציית צפיפות יורדת נתונה f, היתרון המרכזי של הזיגורט הוא זמן הריצה האופטימלי שלו לעומת שיטות אחרות. השיטה הוצגה לראשונה בשנת 1960 ע"י ג'ורג' מרסגליה ועוד כמה מתמטיקאים של שנות ה-60. השיטה מתבססת על כיסוי סופי של השטח מתחת לעקומת הצפיפות ע"י מלבנים אופקיים שווי שטח. אלגוריתם הזיגורט מתבסס על שיטת הדחייה נראה זאת ע"י תיאור כללי של השיטה:
יהי f פונקציית צפיפות יורדת של השתנה הרציף x , נסמן ב C את השטח מתחת לעקומה של f, יתר על כן נבנה סדרה של n מלבנים אופקיים K_i (נסמן Z=⋃_(i=0)^n▒K_i ) כך ש: Z⊃C
נבחר אקראית זוג סדור (x,y) (כמעין חץ אקראי) מ Z עד שניפול בתוך C ואז נחזיר את הערך של x (המשתנה האקראי שייצרנו).
ישנם שלוש סוגיות שנצטרך לדון בהם בכדי לבחור את המלבנים האופקיים:
	שזריקת החץ תהיה מהירה ופשוטה
	שנוכל להריע מהר האם החץ נפל בתוך C
	נרצה לשאוף ל:  1≈(S(C))/(S(Z)) כאשר S פונקציית השטח של Z,C
נפתח את השיטה על סמך דוגמא מנחה:
יהי f(x)=e^(〖-x〗^2/2) פונקציית צפיפות יורדת לכל x≥0.
נבחר לדוגמא ב- 5 מלבנים אופקיים ורצועת בסיס:







במקרה כללי נוכל לבחור את מספר המלבנים כחזקה של 2: 256/128/64.
לכל אחד מה-6 אזורים יש את אותו שטח כך שקל מאוד לבחור בצורה אקראית מלבן כלשהו מכיוון שלכולם יש אותו סיכוי להיבחר ויותר מכך קלה להכריע האם החץ נזרק לתוך C.

אם נבחר מלבן K_i שערכי הx  שלו הם [0,x_i] אז הערך של x בחץ שנזרק נקבע ע"י:
 u∙x_i=x כאשר u∈(0,1) מספר אקראי.
אם x<x_(i-1) אז החץ בתוך C, לא נצטרך בכלל לבדוק מה ערך הy  של החץ.
כעת נוכל להסתכל על רצועת הבסיס כמלבן עד x_5  ועוד זנב לכל x>x_5.
נגדיר משתנה r להיות הx  הכי ימני כך שהזנב הוא x>r=x_5.
במידה ורצועת הבסיס הוגרלה נייצר x אקראי בצורה הבאה: x=(v∙u)/(f(r)) כאשר u∈(0,1)
אם x<r נחזיר את x , אחרת נחזיר את x לבדיקה בזנב לפי y.

דגימה מהזנב:
ראינו כי במקרה בו נבחר ברצועת הבסיס ונקבל x<r נצטרך לדגום מהזנב. נשתמש באלגוריתם נסיגה, מקרה איטי מאוד ביחס ליעילותם של שאר המקרים אבל מכיוון שמקסמנו את השטחים של S,Z הסיכוי לקבל דגימת זנב היא אחת לאלפי צעדים של האלגוריתם המקורי מה שאומר שהיעילות החישובית זניחה ביחס לכול האלגוריתם. 
אלגוריתם הנסיגה לזנב תלוי בד"כ בהתפלגות הנתונה,
למשל לזנב של התפלגות נורמלית נייצר ((-ln⁡(u_1 ))/r,-ln⁡(u_2 ) ) כאשר:u_2  〖,u〗_1∈(0,1) מספרים אקראיים אחידים עד ש: 2y>x^2 ואז תחזיר את הערך r+x
בעוד שלדגימת זנב להתפלגות מעריכית נייצר x=r-ln⁡(u) כאשר u∈(0,1) מספר אקראי אחיד.
נחזור חזרה לבניית אלגוריתם הזיגורט, בצורה הכללית נייצר 255 מלבנים אופקיים ורצועת בסיס ששטחם שווה המלבנים מסתיימים ב: 〖0=x〗_0<⋯<x_255=r, כדי למצוא בדיוק את ערכי הx- נצטרך לעבוד קצת יותר קשה נפתח בהמשך.











האלגוריתם הזיגורט [1]: 
	בוחרים רמה אקראית 0-n:
 1.ערך אקראי U_0∈(0,1)
 2.להחזיר ⌊U_0 n⌋

	אם ⌊U_0 n⌋=0:
             1.ערך אקראי  U_1∈(0,1)
             2. X=U_1∙X_i
             3. אם X<r תחזיר את X
             4.אחרת תעבור לאלגוריתם דגימה מהזנב להתפלגות המתאימה

	אחרת נבחר ערך אקראי  U_2∈(0,1)
             1.X=U_1∙X_(i )
             2. אם X<X_(i+1) תחזיר את X
             3.אחרת תחשב: Y=f(X_i )+U_2∙(f(X_(i+1) )-f(X_i))
                  1.נחשב את הערך של f(X)
                  2.אם Y<f(X) תחזיר את X
                  3.אחרת תחזור לצעד הראשון של האלגוריתם

בחירת המלבנים האופקיים:
יהי f פונקציית צפיפות לכל x≥0, נרצה למצוא 255 (או כל מספר אחר) מלבנים אופקיים ורצועת בסיס אחת כך ששטחם יהיה שווה. יתר על כן נרצה כי השטח של Z יהיה קרוב מאוד לשטח של C. המלבנים יצטרכו להיבחר כך שהשטחים שלהם היו שווים ל-v, החסם הימני של המלבן K_i הוא x_i לכל 1≤i≤255 לכן x_255=r.
כלומר נרצה שלכל 1≤i≤255: x_i [f(x_(i-1) )-f(x_i)]=v
כאשר v=r∙f(r)+∫_r^∞▒f(x)dx, לרוע המזל גם כאשר v נתון לא פשוט למצוא את x_1,…,x_255 המתאימים.
לשם כך נגדיר פונקציית עזר של r כך:
z(r):〖 x〗_255=r;v=r∙f(r)+∫_r^∞▒f(x)dx
לכל i מאינדקס 254 בצעדים של 1- עד 1 תעשה:
x_i=f^(-1) (v/x_(i+1) +f(x_(i+1)))
תחזיר את הערך v-x_1+x_1 f(x_1)
ובכך תיארנו את הבעיה בצורה הבאה - נחפש r כך ש: z(r)=0.
לדוגמא לפונקציית הצפיפות f(x)=e^(〖-x〗^2/2) נחפש r כך ש: z(r)=0 
שלב ראשון נמצא את v:
v=1/256∙∫_0^∞▒〖e^(〖-x〗^2/2) dx=0.00492867〗
שלב שני נמצא את r ע"י המשוואה:
v=r∙e^(〖-r〗^2/2)+∫_r^∞▒〖e^(〖-x〗^2/2) dx〗
לחשב את r שמקיים את המשוואה הנ"ל אינו פשוט נעזר בשיטות נומריות להערכה מספיק טובה של r.
בדוגמתנו r שמקיים את המשוואה הוא r=3.65415 לכן z(r)=0.
לכן, 〖 x〗_255=rונוכל לקבל את כל שאר הx--ים ע"י: x_i=f^(-1) (v/x_(i+1) +f(x_(i+1))).
בכך פתרנו את הבעיה ומצאנו את המלבנים האופקיים יתר על כן,  0.9933≈(S(C))/(S(Z)) אכן קרוב מאוד ל-1 כלומר כיסינו במלבנים אופקיים ורצועת בסיס כמעט באופן מושלם את השטח שמתחת לעקומה של  f〖(x)=e〗^(〖-x〗^2/2).
לסיכום שיטת הזיגורט נועדה להפוך משתנה המתפלג אחיד בקטע מסוים להתפלגות סימטרית אחרת (לרוב התפלגות נורמלית). אחרי שראינו את האלגוריתם ואת בסיס השיטה נסביר איך בדיוק המשתנה שייצרנו  xמתפלג ע"פ פונקציית הצפיפות הנתונה, לא ננמק אלה נראה איך זה מתרחש בפועל.
אם ניקח דגימה אקראית x שהתקבלה ע"י האלגוריתם [1] נוכל לסווג את x להיות באחד מתת הקטעים [0,x_1 ),[x_1,x_2 ),…,[x_254,x_255) ונספור את כמות הx--ים שנפלו לכל אחד מתת הקטעים ונתאר את הגרף כשהסטנוגרמה לדוגמא הקודמת: 


ככול שנגדיל את מספר הערכים האקראיים שנוצרו ע"י האלגוריתם [1] נקבל גרף הסטנוגרמה קרוב מאוד להתפלגות המקורית (פונקציית הצפיפות).
ביבליוגרפיה
[1] Keith Schwartz,(2011),"Darts, Dice and Coins: Sampling from a discrete distribution", Alias Method.
[2] Luc Devroye,(1986),"Non-Uniform Random Variate Generation",2, 27-65, Inversion and Rejection Method.
[3] Luc Devroye,(1986),"Non-Uniform Random Variate Generation",3, 83-98, Inversion Method.
[4] Luc Devroye,(1986),"Non-Uniform Random Variate Generation",3, 113-116, Rejection Method.
[5] Donald E.Knuth,(1997),"The Art Of Computer Programming", Volume 2, 41-67, Statistic Tests.
[6] GINAR,(2018),"Diehard – battery of statistic tests", Statistic Tests.
[7] Luc Devroye,(1986),"Non-Uniform Random Variate Generation",3, 107-112, Alias Method.
[8] George Marsaglia, Wai Wan Tsang,(2000),"The Ziggurat Method for Generating Random Variables", Ziggurat Algorithm.
[9] Idan Alter,(2023),"Rejection Sampling and the Ziggurat Algorithm", Ziggurat Algorithm


